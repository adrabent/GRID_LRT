{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID_LRT Testbed Notebook\n",
    "\n",
    "## 1. Setting up the Environment\n",
    "\n",
    "The GRID LOFAR TOOLS have several infrastructure requirements. They are as follows:\n",
    "\n",
    "1. ASTRON LOFAR staging credentials\n",
    "2. PiCaS database access\n",
    "3. Valid GRID proxy\n",
    "\n",
    "\n",
    "Here, we'll test that all of the above are enabled and work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/apmechev/test/lib/python2.7/site-packages/GRID_LRT-0.2-py2.7.egg/GRID_LRT/__init__.pyc\n",
      "2018-01-17 13:34:08.535049 stager_access: Parsing user credentials from /home/apmechev/.awe/Environment.cfg\n",
      "2018-01-17 13:34:08.535237 stager_access: Creating proxy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import GRID_LRT\n",
    "print(GRID_LRT.__file__)\n",
    "import subprocess\n",
    "from GRID_LRT.get_picas_credentials import picas_cred\n",
    "from GRID_LRT.Staging import stage_all_LTA\n",
    "from GRID_LRT.Staging import state_all\n",
    "from GRID_LRT.Staging import stager_access\n",
    "from GRID_LRT import Token\n",
    "pc=picas_cred()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give a confirmation of that your LOFAR ASTRON credentials were properly read:\n",
    "\n",
    "`2017-12-04 17:15:29.097902 stager_access: Parsing user credentials from /home/apmechev/.awe/Environment.cfg\n",
    "2017-12-04 17:15:29.097973 stager_access: Creating proxy`\n",
    "\n",
    "Next, we check that your PiCaS User and Database are set properly. You can also verify your password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apmechev\n",
      "sksp_unittest\n"
     ]
    }
   ],
   "source": [
    "print(pc.user)\n",
    "print(pc.database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the test srm.txt to show off our staging chops:\n",
    "\n",
    "Stage the test srm.txt file. You'll get a StageID that you can use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging in Juleich\n",
      "Setting up 1 srms to stage\n",
      "staged with stageID  18405\n",
      "18405\n"
     ]
    }
   ],
   "source": [
    "os.path.exists('/home/apmechev/test/GRID_LRT/srm.txt')\n",
    "stageID=stage_all_LTA.main('/home/apmechev/test/GRID_LRT/srm.txt') # NOTE! You'll get two emails every time you do this!\n",
    "print(stageID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now re-run the cell below to check the current status of your staging request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "stage_all_LTA.get_stage_status(stageID) #crashes (py2.7?)\n",
    "#The code below can also show you a more detailed status\n",
    "statuses=stager_access.get_progress()\n",
    "\n",
    "print(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staging status no longer in LTA Database\n"
     ]
    }
   ],
   "source": [
    "statuses=stager_access.get_progress()\n",
    "## When the staging completes, your stageID magically disappears from the database\n",
    "# Neat, huh?\n",
    "if not statuses:\n",
    "    print \"Staging status no longer in LTA Database\" #This happens because bad programming\n",
    "else:\n",
    "    stager_access.prettyprint(statuses[str(stageID)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the status of the srms two different ways (with srmls and with gfal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L556776_SB230_uv.MS_ac189f93.tar --> ONLINE_AND_NEARLINE\n"
     ]
    }
   ],
   "source": [
    "## state_all.main('srm.txt') #gfal2 Doesn't work anymore?\n",
    "for i in open('srm.txt','rb').readlines(): #Using srmls to loop over files ¯\\_(ツ)_/¯\n",
    "    out = subprocess.Popen(['srmls','-l',i],stdout=subprocess.PIPE).communicate()[0]\n",
    "    print(i.split('/')[-1].strip()+\" --> \"+out.split('locality:')[1].split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokens! \n",
    "### 2. a) The manual way\n",
    "\n",
    "Next we'll interface with PiCaS and start making tokens for our Observation:\n",
    "\n",
    "here we need a string to link all the tokens in one Observation. We'll use the string 'demo_'+username in the sksp_dev database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_token_ID = t_demo_apmechev_manual\n"
     ]
    }
   ],
   "source": [
    "uname = os.environ['USER']\n",
    "th = Token.Token_Handler(t_type=\"demo_\"+uname, uname=pc.user, pwd=pc.password, dbn='sksp_dev')\n",
    "\n",
    "#Create the overview_view (has the number of todo, done, error, running, [...] tokens)\n",
    "th.add_overview_view()\n",
    "\n",
    "#Add the satus views (By default 'todo', 'locked', 'done', 'error')\n",
    "th.add_status_views()\n",
    "\n",
    "#Manually create a token:\n",
    "manual_keys = {'manual_key':'manual_value','manual_int':1024}\n",
    "man_token_1 = th.create_token(keys=manual_keys, append=\"manual\") #will return the id of the manual token\n",
    "print('manual_token_ID = ' + man_token_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also manually create a Token with an automatic attachment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two attached files are: ['srm_at_token_create.txt', 'srm_added_later.txt']\n",
      "\n",
      "The attachemnt srm_at_token_create.txt was saved at /home/apmechev/test/GRID_LRT/srm_at_token_create.txt\n"
     ]
    }
   ],
   "source": [
    "manual_keys = {'manual_key':'manual_value','manual_int':0}\n",
    "man_token_2 = th.create_token(keys=manual_keys, \n",
    "                            append=\"manual_with_attach\",\n",
    "                            attach=[open('srm.txt'),'srm_at_token_create.txt']) \n",
    "\n",
    "##We can also attach files after the token's been created:\n",
    "th.add_attachment(man_token_2, open('srm.txt'), 'srm_added_later.txt')\n",
    "\n",
    "#Double check that both files were attached. Returns a list of filenames:\n",
    "man_2_attachies = th.list_attachments(man_token_2)\n",
    "print(\"The two attached files are: \"+str(man_2_attachies))\n",
    "\n",
    "# We can also of course download attachments:\n",
    "saved_attach=th.get_attachment(man_token_2,man_2_attachies[0],savename=man_2_attachies[0])\n",
    "print(\"\")\n",
    "print('The attachemnt '+str(man_2_attachies[0])+\" was saved at \"+saved_attach)\n",
    "\n",
    "assert(os.path.exists(saved_attach))\n",
    "os.remove(saved_attach)\n",
    "assert(not os.path.exists(saved_attach))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also list the views and the tokens from each view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['todo', 'done', 'overview_total', 'locked', 'error']\n",
      "<class 'GRID_LRT.couchdb.client.ViewResults'>\n",
      "There are 0 'locked' tokens\n",
      "There are 2 'todo' tokens\n",
      "\n",
      "They are:\n",
      "(\"CouchDB token keys: ['key', 'id', 'value']\", 'Token ID: t_demo_apmechev_manual')\n",
      "(\"CouchDB token keys: ['key', 'id', 'value']\", 'Token ID: t_demo_apmechev_manual_with_attach')\n"
     ]
    }
   ],
   "source": [
    "print(th.views.keys()) #the views member of th is a dictionary of views \n",
    "locked_tokens = th.list_tokens_from_view('locked')\n",
    "\n",
    "print(type(done_tokens)) #It's not a list!!\n",
    "print(\"There are \"+str(len(locked_tokens))+\" 'locked' tokens\")\n",
    "\n",
    "\n",
    "todo_tokens = th.list_tokens_from_view('todo') \n",
    "# It's not a list because it procedurally pings CouchDB, ~generator\n",
    "#Use the help below to browse how it works!!\n",
    "##help(todo_tokens)\n",
    "\n",
    "print(\"There are \"+str(len(todo_tokens))+\" 'todo' tokens\")\n",
    "print(\"\")\n",
    "print(\"They are:\")\n",
    "for i in todo_tokens:\n",
    "    print(\"CouchDB token keys: \"+str(i.keys()),\"Token ID: \"+i.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set all tokens in a view to a Status, say 'locked'. This automatically locks the tokens!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lock status of the token: 0.\n",
      "Scrub count of the token: 0.\n",
      "There are 2 'todo' tokens\n",
      "There are 0 'locked' tokens\n",
      "\n",
      "Setting status to locked for all todo tokens\n",
      "\n",
      "There are 0 'todo' tokens\n",
      "There are 2 'locked' tokens\n",
      "Lock status of the token: 1.\n",
      "\n",
      "Resetting the locked tokens\n",
      "Scrub count of the token: 1.\n",
      "There are 2 'todo' tokens\n",
      "There are 0 'locked' tokens\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Lock status of the token: '+str(th.db[man_token_2]['lock'])+\".\")\n",
    "print('Scrub count of the token: '+str(th.db[man_token_2]['scrub_count'])+\".\")\n",
    "print(\"There are \"+str(len(th.list_tokens_from_view('todo')))+\" 'todo' tokens\")\n",
    "print(\"There are \"+str(len(th.list_tokens_from_view('locked')))+\" 'locked' tokens\")\n",
    "print(\"\")\n",
    "print(\"Setting status to locked for all todo tokens\")\n",
    "th.set_view_to_status(view_name='todo',status='locked') #Sets all todo tokens to \"locked\"\n",
    "\n",
    "todo_tokens = th.list_tokens_from_view('todo') \n",
    "print(\"\")\n",
    "\n",
    "print(\"There are \"+str(len(todo_tokens))+\" 'todo' tokens\")\n",
    "### No more todo tokens!\n",
    "\n",
    "\n",
    "locked_tokens = th.list_tokens_from_view('locked')\n",
    "print(\"There are \"+str(len(locked_tokens))+\" 'locked' tokens\")\n",
    "##Now they're all locked!\n",
    "\n",
    "print('Lock status of the token: '+str(th.db[man_token_2]['lock'])+\".\")\n",
    "#You can reset all tokens from a view back to 'todo'. This increments the scrub_count field\n",
    "\n",
    "\n",
    "resetted_tokens=th.reset_tokens('locked')\n",
    "print(\"\")\n",
    "print(\"Resetting the locked tokens\")\n",
    "print('Scrub count of the token: '+str(th.db[man_token_2]['scrub_count'])+\".\")\n",
    "print(\"There are \"+str(len(th.list_tokens_from_view('todo')))+\" 'todo' tokens\")\n",
    "print(\"There are \"+str(len(th.list_tokens_from_view('locked')))+\" 'locked' tokens\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can create your own view. Views collect tokens that satisfy a certain boolean expression (where the token is referenced as 'doc'\n",
    "\n",
    "For example: \n",
    "\n",
    "The todo view satsifies: `'doc.lock ==  0 && doc.done == 0 '` \n",
    "\n",
    "The locked view satisfies: `'doc.lock > 0 && doc.done == 0 '`\n",
    "\n",
    "The done view satsifies: `'doc.status == \"done\" '`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ViewDefinition '_design/demo_apmechev/_view/demo_view'>\n",
      "There is 1 tokens in the demo_view\n",
      "There are 3 tokens in the demo_view\n"
     ]
    }
   ],
   "source": [
    "th.add_view(v_name=\"demo_view\",cond='doc.manual_int == 0 ') #Only one of our tokens has manual_int==0\n",
    "print(th.views['demo_view']) #new view is here!\n",
    "\n",
    "assert(len(th.list_tokens_from_view('demo_view'))==1)\n",
    "print(\"There is \"+str(len(th.list_tokens_from_view('demo_view')))+\" tokens in the demo_view\")\n",
    "\n",
    "#Creating 2 more tokens for this view. If append isn't changed, the id is the same, so\n",
    "#new tokens won't be created! But you can imagine a loop will make creation easy right?\n",
    "_ = th.create_token(keys=manual_keys, \n",
    "                            append=\"manual_with_attach_1\",  \n",
    "                            attach=[open('srm.txt'),'srm_at_token_create.txt']) \n",
    "_ = th.create_token(keys=manual_keys, \n",
    "                            append=\"manual_with_attach_2\",\n",
    "                            attach=[open('srm.txt'),'srm_at_token_create.txt'])\n",
    "print(\"There are \"+str(len(th.list_tokens_from_view('demo_view')))+\" tokens in the demo_view\")\n",
    "assert(len(th.list_tokens_from_view('demo_view'))==3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can delete all tokens in this view easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Token t_demo_apmechev_manual_with_attach\n",
      "Deleting Token t_demo_apmechev_manual_with_attach_1\n",
      "Deleting Token t_demo_apmechev_manual_with_attach_2\n",
      "There are 0 tokens in the demo_view\n"
     ]
    }
   ],
   "source": [
    "th.delete_tokens('demo_view')\n",
    "assert(len(th.list_tokens_from_view('demo_view'))==0)\n",
    "print(\"There are \"+str(len(th.list_tokens_from_view('demo_view')))+\" tokens in the demo_view\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now introducing Token Sets: Just an easy way to create tokens from a dictionary using a yaml file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts=Token.TokenSet(th=th)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
